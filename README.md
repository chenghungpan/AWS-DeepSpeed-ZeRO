# Deploying GPT-J with DeepSpeed on AWS Sagemaker

This repository demonstrates how you can accelerate GPT-J with DeepSpeed Inference and deploy it on AWS SageMaker.

## LLM Model Size Grows Exponentially  

<img src="ZERO-1.png" alt="Alt text for the image" width="1000"/>

## DeepSpeefd ZeRO (Zero Redundancy Optimization)

<img src="ZERO-2.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-3.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-4.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-5.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-6.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-7.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-8.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-9.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-10.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-11.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-12.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-13.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-14.png" alt="Alt text for the image" width="1000"/>
<img src="ZERO-15.png" alt="Alt text for the image" width="1000"/>
