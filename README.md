# Deploying GPT-J with DeepSpeed on AWS Sagemaker

This repository demonstrates how you can accelerate GPT-J with DeepSpeed Inference and deploy it on AWS SageMaker.

## LLM Sizes Grow Exponentially  

<img src="img/ZERO-1.png" alt="Alt text for the image" width="1000"/>


<img src="img/ZERO-2.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-3.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-4.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-5.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-6.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-7.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-8.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-9.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-10.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-11.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-12.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-13.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-14.png" alt="Alt text for the image" width="1000"/>
<img src="img/ZERO-15.png" alt="Alt text for the image" width="1000"/>
