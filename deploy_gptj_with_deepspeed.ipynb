{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c412f6",
   "metadata": {},
   "source": [
    "# Building your own algorithm container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a01a2",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate how to run GPT-J with DeepSpeed locally and then deploy it in a SageMaker Inference Endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ee044",
   "metadata": {},
   "source": [
    "# 1. Prepare docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a5c9e",
   "metadata": {},
   "source": [
    "Open a terminal session in the `../accelerating_gptj_with_deepspeed/` directory and run `build.sh` bash script. This script performs the following steps:\n",
    "\n",
    "* Makes `serve` executable and builds our docker image\n",
    "* Downloads GPT-J in half precision to the `./run_local/test_dir/` if that directory is empty.\n",
    "* Optionally, runs the container for local testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edd541",
   "metadata": {},
   "source": [
    "To run with local testing, make `build.sh` executable:\n",
    "\n",
    "```sh\n",
    "chmod +x ./build.sh\n",
    "```\n",
    "\n",
    "Then run: \n",
    "\n",
    "```sh\n",
    "./build.sh gptj-inference-endpoint test_local\n",
    "```\n",
    "\n",
    "Or, to run without local testing, run:\n",
    "\n",
    "```sh\n",
    "./build.sh gptj-inference-endpoint\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f64470a",
   "metadata": {},
   "source": [
    "# 2. Local Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc6448",
   "metadata": {},
   "source": [
    "To test the endpoint, you can run the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bc206e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys \n",
    "\n",
    "URL = 'http://127.0.0.1:8080/invocations'\n",
    "HEADERS = {'Content-type': 'application/json', 'Accept': '*/*'}\n",
    "\n",
    "def test_endpoint(text, parameters):\n",
    "    \n",
    "    data = {\n",
    "        \"inputs\":{\n",
    "            \"text_inputs\": text,\n",
    "            \"parameters\": parameters\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    payload = json.dumps(data)\n",
    "    response = requests.post(URL, json=data, headers=HEADERS)\n",
    "    \n",
    "    return(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8fbc737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a creative writing exercise. Below, you'll be given a prompt. Your story should be based on the prompt.\n",
      "\n",
      "Prompt: A scary story about a haunted mouse\n",
      "Story: On a dark and stormy night, the mouse crept in the shadows.  He watched as his food was stolen from out of his reach. His family was being taken away because they didn't have enough food to eat. The mouse decided that he would rather die than starve. So, the mouse made up his mind to jump into the trap set for him. He waited until it set, and jumped onto the trap. The trap closed and when he realized what had happened, he could not move. He screamed but no one came to help him. That morning, the mouse found himself in a small cage with two other mice. \"What's going on?\" Said the first mouse. \"We are here because we don't have enough food. And because we can't escape.\" Said the second mouse. \"I don't want to live in this tiny little place\" said the first mouse.. \"I'm scared.\" Said the second mouse. \"Scared? What's there to be afraid of? We're just animals living among each other. And I know how to\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"This is a creative writing exercise. Below, you'll be given a prompt. Your story should be based on the prompt.\n",
    "\n",
    "Prompt: A scary story about a haunted mouse\n",
    "Story: On a dark and stormy night, the mouse crept in the shadows. \"\"\"\n",
    "\n",
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_new_tokens\":200,\n",
    "    \"min_tokens\": 100,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"top_p\": 500,\n",
    "    }\n",
    "\n",
    "response = json.loads(test_endpoint(text, parameters))\n",
    "print(response['response'][0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb6f574",
   "metadata": {},
   "source": [
    "# 3. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa95e3",
   "metadata": {},
   "source": [
    "When you're satisfied with your container, you can rebuild and push your container to AWS ECR using the `push_to_ecr.sh` script.\n",
    "\n",
    "For example, to push the image we built above, named \"gptj-inference-endpoint\", you can use the `push_to_ecr.sh` script, which requires the name of your docker image and the s3 path where you want to store the model weights.\n",
    "\n",
    "Specifically, run the following in your terminal session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d70fc",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "export image=gptj-inference-endpoint\n",
    "export s3Uri=s3://<your_bucket_here>/gptj-float16/model.tar.gz\n",
    "chmod +x push_to_ecr.sh\n",
    "./push_to_ecr.sh $image $s3Uri\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec609e",
   "metadata": {},
   "source": [
    "First, this script will push your image to ECR. For reference later, note the address of the repository that the container is pushed to. It should appear below the line `Login Succeeded` in the output from the call to `push_to_ecr.sh`. Then it will tar the model weights you downloaded and push them to the s3Uri you've specified. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffcfbc0",
   "metadata": {},
   "source": [
    "# 4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95267a4a",
   "metadata": {},
   "source": [
    "Now, you can deploy your endpoint as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d04d32c",
   "metadata": {},
   "source": [
    "### 4.1 Initialize configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e5a21d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "import time \n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Specify s3uri for model.tar.gz\n",
    "model_data = \"\"\n",
    "\n",
    "# Specify path to gptj-inference-endpoint image in ECR\n",
    "image = \"\"\n",
    "\n",
    "# Specify sagemaker model_name\n",
    "sm_model_name = \"gptj-completion-gpu-test\"\n",
    "\n",
    "# Specify endpoint_name\n",
    "endpoint_name = \"gptj-completion-gpu-test\"\n",
    "\n",
    "# Specify instance_type\n",
    "instance_type = 'ml.g4dn.2xlarge'\n",
    "\n",
    "# Specify initial_instance_count\n",
    "initial_instance_count = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174c343",
   "metadata": {},
   "source": [
    "### 4.2 Initialize endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e517e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model = Model(model_data = model_data, \n",
    "                        image_uri = image,\n",
    "                        role = role,\n",
    "                        predictor_cls=RealTimePredictor,\n",
    "                        name = sm_model_name)\n",
    "\n",
    "predictor = sm_model.deploy(\n",
    "        instance_type=instance_type,\n",
    "        initial_instance_count=1,\n",
    "        endpoint_name = endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1930e31",
   "metadata": {},
   "source": [
    "### 4.3 Query model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac1ea39",
   "metadata": {},
   "source": [
    "To query your endpoint, you can use the code below. Also, remember that you can pass any parameters accepted by the HuggingFace `\"text-generation\"` pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd35d6",
   "metadata": {},
   "source": [
    "#### Initialize asynchronous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2314181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json \n",
    "\n",
    "# Get the boto3 session and sagemaker client, as well as the current execution role\n",
    "sess = boto3.Session()\n",
    "\n",
    "# Specify your AWS Region\n",
    "aws_region=sess.region_name\n",
    "\n",
    "\n",
    "# Create a low-level client representing Amazon SageMaker Runtime\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name=aws_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "text = \"\"\"This is a creative writing exercise. Below, you'll be given a prompt. Your story should be based on the prompt.\n",
    "\n",
    "Prompt: A scary story about a haunted mouse\n",
    "Story: On a dark and stormy night, the mouse crept in the shadows. \"\"\"\n",
    "\n",
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_new_tokens\":200,\n",
    "    \"min_tokens\": 100,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"top_p\": 500,\n",
    "    }\n",
    "\n",
    "data = {\n",
    "    \"inputs\": {\n",
    "        \"text_inputs\": text,\n",
    "        \"parameters\": parameters\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "body = json.dumps(data)\n",
    "\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint( \n",
    "        EndpointName=endpoint_name, \n",
    "        Body = body, \n",
    "        ContentType = 'application/json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47746c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "body = json.dumps(data)\n",
    "\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint( \n",
    "        EndpointName=endpoint_name, \n",
    "        Body = body, \n",
    "        ContentType = 'application/json'\n",
    ")\n",
    "\n",
    "result = json.loads(response['Body'].read().decode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
